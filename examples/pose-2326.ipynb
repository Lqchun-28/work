{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMbO5uRUBReUS/0Jb2M9cft"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-A2Rf9VxjdQ4","executionInfo":{"status":"ok","timestamp":1747493063901,"user_tz":-480,"elapsed":13354,"user":{"displayName":"李乾春","userId":"14178874092833220010"}},"outputId":"708ba622-761f-4fe8-8271-29ab95e41b05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YR4p8_claKd","executionInfo":{"status":"ok","timestamp":1747493070821,"user_tz":-480,"elapsed":4232,"user":{"displayName":"李乾春","userId":"14178874092833220010"}},"outputId":"e7874bc9-8d91-49e9-8947-d71c2d3eea09"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnxruntime\n","  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n"]}]},{"cell_type":"markdown","source":["#导入依赖"],"metadata":{"id":"M1vsv00_mQBf"}},{"cell_type":"code","source":["!pip install onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JZMCUyNmoXI","executionInfo":{"status":"ok","timestamp":1747494716203,"user_tz":-480,"elapsed":2111,"user":{"displayName":"李乾春","userId":"14178874092833220010"}},"outputId":"07eccc35-56aa-4c5c-9301-ee85f5d40739"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.22.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n"]}]},{"cell_type":"code","source":["import onnxruntime as ort\n","import numpy as np\n","import cv2\n","from collections import deque"],"metadata":{"id":"wgF1fNdjkX-O","executionInfo":{"status":"ok","timestamp":1747494721764,"user_tz":-480,"elapsed":173,"user":{"displayName":"李乾春","userId":"14178874092833220010"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["#模型加载"],"metadata":{"id":"c4qVaSJtmVkk"}},{"cell_type":"code","source":["#!wget https://ftrg.zbox.filez.com/v2/delivery/data/95f00b0fc900458ba134f8b180b3f7a1/examples/yolov8_pose/yolov8n-pose.onnx\n","session = ort.InferenceSession(\"/content/yolov8n-pose.onnx\")\n","input_name = session.get_inputs()[0].name\n","output_name = session.get_outputs()[0].name"],"metadata":{"id":"-71a1ovhlYmE","executionInfo":{"status":"ok","timestamp":1747495127634,"user_tz":-480,"elapsed":39,"user":{"displayName":"李乾春","userId":"14178874092833220010"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["#图像预处理函数"],"metadata":{"id":"mh-9G2y1mbjy"}},{"cell_type":"code","source":["def letterbox_resize(image, size, bg_color=114):\n","    target_width, target_height = size\n","    image_height, image_width = image.shape[:2]\n","    scale = min(target_width / image_width, target_height / image_height)\n","    new_size = (int(image_width * scale), int(image_height * scale))\n","    resized = cv2.resize(image, new_size)\n","    canvas = np.full((target_height, target_width, 3), bg_color, dtype=np.uint8)\n","    offset_x = (target_width - new_size[0]) // 2\n","    offset_y = (target_height - new_size[1]) // 2\n","    canvas[offset_y:offset_y + new_size[1], offset_x:offset_x + new_size[0]] = resized\n","    return canvas, scale, offset_x, offset_y"],"metadata":{"id":"5HAIzaENoDuW","executionInfo":{"status":"ok","timestamp":1747495344357,"user_tz":-480,"elapsed":12,"user":{"displayName":"李乾春","userId":"14178874092833220010"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["#姿态分类函数"],"metadata":{"id":"efa_L1ESoEqi"}},{"cell_type":"code","source":["def classify_pose_state(keypoints_history, move_thresh=8, fall_angle_thresh=30):\n","    if len(keypoints_history) < 2:\n","        return \"静止\"\n","\n","    prev = keypoints_history[-2][:, :2]\n","    curr = keypoints_history[-1][:, :2]\n","    movement = np.linalg.norm(curr - prev, axis=1).mean()\n","\n","    try:\n","        shoulder = curr[5], curr[6]\n","        hip = curr[11], curr[12]\n","    except IndexError:\n","        return \"静止\"\n","\n","    def angle(p1, p2):\n","        dx, dy = p2[0] - p1[0], p2[1] - p1[1]\n","        return np.degrees(np.arctan2(dy, dx))\n","\n","    torso_angle = angle(np.mean(shoulder, axis=0), np.mean(hip, axis=0))\n","\n","    if abs(torso_angle) < fall_angle_thresh:\n","        return \"摔倒\"\n","    elif movement > move_thresh:\n","        return \"行走\"\n","    else:\n","        return \"静止\"\n"],"metadata":{"id":"RN5i23MEoZP-","executionInfo":{"status":"ok","timestamp":1747495346333,"user_tz":-480,"elapsed":6,"user":{"displayName":"李乾春","userId":"14178874092833220010"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["#单张图片测试\n","\n"],"metadata":{"id":"_phII5OFoc7-"}},{"cell_type":"code","source":["def run_pose_onnx(image_path, onnx_path):\n","    # 加载模型\n","    session = ort.InferenceSession(onnx_path)\n","    input_name = session.get_inputs()[0].name\n","\n","    # 图像预处理\n","    img_raw = cv2.imread(image_path)\n","    img, scale, ox, oy = letterbox_resize(img_raw, (640, 640))\n","    img_input = img[..., ::-1].astype(np.float32) / 255.0  # BGR to RGB\n","    img_input = np.transpose(img_input, (2, 0, 1))  # HWC to CHW\n","    img_input = np.expand_dims(img_input, axis=0)\n","\n","    # ONNX 推理\n","    outputs = session.run(None, {input_name: img_input})\n","    preds = outputs[0]  # shape: [1, N, 56]\n","\n","    keypoints_history = deque(maxlen=5)\n","\n","    for det in preds[0]:\n","        conf = det[4]\n","        cls = det[5]\n","        if conf < 0.3 or int(cls) != 0:  # 只处理person\n","            continue\n","\n","        # 关键点提取 [17×3]\n","        kpts = det[6:].reshape(17, 3)  # [x, y, conf]\n","        kpts[:, 0] = (kpts[:, 0] - ox) / scale\n","        kpts[:, 1] = (kpts[:, 1] - oy) / scale\n","\n","        keypoints_history.append(kpts)\n","        if len(keypoints_history) < 2:\n","            state = \"静止\"\n","        else:\n","            state = classify_pose_state(keypoints_history)\n","\n","        # 可视化\n","        for x, y, c in kpts:\n","            if c > 0.3:\n","                cv2.circle(img_raw, (int(x), int(y)), 4, (0, 255, 0), -1)\n","\n","        cv2.putText(img_raw, f\"状态: {state}\", (10, 30),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","    cv2.imshow(\"ONNX Pose Detection\", img_raw)\n","    cv2.waitKey(0)\n","    cv2.destroyAllWindows()\n","\n"],"metadata":{"id":"UnFTumlkoggC","executionInfo":{"status":"ok","timestamp":1747495347832,"user_tz":-480,"elapsed":3,"user":{"displayName":"李乾春","userId":"14178874092833220010"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["run_pose_onnx(\"/content/drive/MyDrive/yolo-pose/people(1602).jpg\", \"/content/yolov8n-pose.onnx\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"VFJ03K_Zo6VZ","executionInfo":{"status":"error","timestamp":1747495374650,"user_tz":-480,"elapsed":178,"user":{"displayName":"李乾春","userId":"14178874092833220010"}},"outputId":"9a96e833-8049-4ebe-c115-4c15bf451e4c"},"execution_count":34,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-2d28a6918574>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_pose_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/yolo-pose/people(1602).jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/yolov8n-pose.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-33-051d2519676b>\u001b[0m in \u001b[0;36mrun_pose_onnx\u001b[0;34m(image_path, onnx_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 只处理person\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"KLu8TXYxqF8Q","executionInfo":{"status":"error","timestamp":1747493934822,"user_tz":-480,"elapsed":8,"user":{"displayName":"李乾春","userId":"14178874092833220010"}},"outputId":"24ea258a-02eb-4e29-9a2c-3c3b563ca0c9"},"execution_count":17,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'image' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-28935580a9bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-xVtO_Z7qQQQ"},"execution_count":null,"outputs":[]}]}